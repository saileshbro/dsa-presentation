\documentclass[aspectratio=169]{beamer}
% For best font rendering with XeLaTeX/LuaLaTeX
\usepackage{fontspec}
\usepackage{unicode-math}
\usepackage{tikz}
\usepackage{colortbl}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{biblatex}

% TikZ libraries
\usetikzlibrary{arrows,automata,positioning,shapes,calc,decorations.pathmorphing,patterns,math}

% Beamer theme
\usetheme{metropolis}

% Title page info
\title{Probabilistic Algorithms: What, Why, and How}
\subtitle{A Deep Dive into Randomness in Computing}
\author{Sailesh Dahal}
\institute{Kathmandu University}
\date{\today}

% Bibliography
\addbibresource{refs.bib}

% Listings configuration
\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny,
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    showstringspaces=false
}

\begin{document}

\begin{frame}
  \begin{tikzpicture}[remember picture,overlay]
    \node[anchor=south east, xshift=-5mm, yshift=5mm] at (current page.south east) {
      \includegraphics[width=2cm]{../assets/ku_logo.png}
    };
  \end{tikzpicture}
  \titlepage
\end{frame}

% Outline frame
\begin{frame}{Outline}
  \tableofcontents
\end{frame}

% What are Probabilistic Algorithms?
\section{What are Probabilistic Algorithms?}
\begin{frame}{What is a Probabilistic Algorithm?}
  \begin{block}{Definition}
    An algorithm that makes random choices during execution to influence its behavior or output.
  \end{block}

  \begin{itemize}
    \item Output or performance may vary on different runs
    \item Two main types: Las Vegas (always correct, time varies), Monte Carlo (time fixed, may err)
  \end{itemize}
\end{frame}

\begin{frame}{Types of Probabilistic Algorithms}
  \begin{itemize}
    \item \textbf{Las Vegas:} Always correct, random running time

    \item \textbf{Monte Carlo:} Fixed running time, may give incorrect result with small probability

    \item \textbf{Example:} Randomized Quicksort (Las Vegas)

    \item \textbf{Example:} Primality testing (Monte Carlo)
  \end{itemize}
\end{frame}

% Why use Probabilistic Algorithms?
\section{Why Probabilistic Algorithms?}
\begin{frame}{Why Randomness?}
  \begin{block}{Motivation}
    \begin{itemize}
      \item Simpler algorithms

      \item Better expected performance

      \item Avoid worst-case scenarios

      \item Useful for large-scale and distributed systems
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}{Real-World Motivation}
  \begin{itemize}
    \item Web search (PageRank)

    \item Load balancing (power of two choices)

    \item Hashing (universal hash functions)

    \item Primality testing (Miller-Rabin)
  \end{itemize}
\end{frame}

% How do Probabilistic Algorithms work?
\section{How do Probabilistic Algorithms Work?}
\begin{frame}{How: Randomization in Algorithms}
  \begin{block}{Key Idea}
    Use random choices to influence the algorithm's path or output.
  \end{block}

  \begin{itemize}
    \item Random pivot in Quicksort

    \item Random walks in graphs

    \item Random sampling
  \end{itemize}
\end{frame}

% Example: Randomized Quicksort
\section{Example: Randomized Quicksort}

% New slide: QuickSort vs Randomized QuickSort steps
\begin{frame}{QuickSort vs Randomized QuickSort}
\textbf{QuickSort:}
\begin{enumerate}
  \item Pick a pivot element from the array
  \item Split array into 3 subarrays: those smaller than pivot, those larger than pivot, and the pivot itself
  \item Recursively sort the subarrays, and concatenate them
\end{enumerate}
  \vspace{1em}
  \textbf{Randomized QuickSort:}
  \begin{enumerate}
    \item Pick a pivot element \textbf{uniformly at random} from the array
    \item Split array into 3 subarrays: those smaller than pivot, those larger than pivot, and the pivot itself
    \item Recursively sort the subarrays, and concatenate them
  \end{enumerate}
  \end{frame}

% New slide: Worst-case for QuickSort
\begin{frame}{Example: Randomized Quicksort}
  \textbf{Recall:} QuickSort can take $\Omega(n^2)$ time to sort an array of size $n$.
\end{frame}

% New slide: Theorem and expectation for Randomized QuickSort
\begin{frame}{Randomized QuickSort: Expected Runtime}
\textbf{Theorem}
\begin{block}{}
  Randomized QuickSort sorts a given array of length $n$ in $O(n \log n)$ expected time.
\end{block}
  \vspace{1em}
  \textbf{Note:} On every input, randomized QuickSort takes $O(n \log n)$ time in expectation. On every input, it may take $\Omega(n^2)$ time with some small probability.
\end{frame}

\input{../programs/quicksort/quicksort_steps.tex}
\input{../programs/pi_calculation/pi_calculation_steps.tex}

\section{Analysis: Recurrence and Expectation}
\begin{frame}{Quicksort Recurrence}
  \begin{block}{Expected Comparisons}
    \[
      T(n) \leq n + \frac{1}{n} \sum_{i=1}^n (T(i-1) + T(n-i))
    \]

    Base case: $T(1) = 0$

    Solution: $T(n) = O(n \log n)$
  \end{block}
\end{frame}

\begin{frame}{Slick Analysis: Indicator Variables}
  \begin{itemize}
    \item $Q(A)$: Number of comparisons on input $A$

    \item $X_{ij}$: Indicator for whether elements $i$ and $j$ are compared

    \item $E[Q(A)] = \sum_{i<j} Pr[R_{ij}]$

    \item $Pr[R_{ij}] = \frac{2}{j-i+1}$
  \end{itemize}

  \begin{block}{Visualization}
    \begin{center}
      % Insert comparison probability diagram here
      \begin{tikzpicture}[scale=1, every node/.style={scale=1}]
        % Draw array boxes
        \foreach \i in {1,...,8} {
            \draw (\i,0) rectangle (\i+1,1);
            \node at (\i+0.5,0.5) {\i};
          }
        % Highlight i and j
        \fill[green!20] (2,0) rectangle (3,1);
        \fill[blue!20] (7,0) rectangle (8,1);
        \node at (2.5,0.5) {$i$};
        \node at (7.5,0.5) {$j$};
        % Draw arc between i and j
        \draw[thick,red,->] (2.5,1) .. controls (4.5,2.5) and (6.5,2.5) .. (7.5,1);
        \node[red] at (5,2.7) {Probability $2/(j-i+1)$};
      \end{tikzpicture}
    \end{center}
  \end{block}
\end{frame}

\begin{frame}{Harmonic Numbers in Analysis}
  \begin{block}{Harmonic Number}
    $H_n = \sum_{i=1}^n \frac{1}{i} = \Theta(\log n)$
  \end{block}

  \begin{block}{Summation in Quicksort}
    $E[Q(A)] \leq 2nH_n = O(n \log n)$
  \end{block}
\end{frame}

% Example: Coin Toss Probability
\section{Example: Coin Toss Probability}
\begin{frame}{Coin Toss Example}
  \begin{block}{Experiment}
    John tosses a biased coin (probability $p$ of heads) to decide whether to wear a tie. If heads, tosses a fair coin to pick red or blue tie.
  \end{block}

  \begin{block}{Question}
    What is the probability John wears a red tie on the first day he wears a tie?
  \end{block}

  \begin{center}
    % Insert coin toss diagram here
    \begin{tikzpicture}[level distance=1.5cm,
        level 1/.style={sibling distance=3cm},
        level 2/.style={sibling distance=2cm}]
      \node {Start}
      child {node {Tie ($p$)}
          child {node {Red (0.5)}}
          child {node {Blue (0.5)}}
        }
      child {node {No Tie ($1-p$)}};
    \end{tikzpicture}
  \end{center}
\end{frame}

% Where do random bits come from?
\section{Random Bits in Practice}
\begin{frame}{Where do Random Bits Come From?}
  \begin{itemize}
    \item Hardware random number generators

    \item Pseudo-random number generators (PRNGs)

    \item Physical phenomena (thermal noise, radioactive decay)

    \item In practice, PRNGs are sufficient for most applications
  \end{itemize}
\end{frame}

% Probabilistic Data Structures
\section{Probabilistic Data Structures}

\begin{frame}{What is a Probabilistic Data Structure?}
  \begin{block}{Definition}
    Data structures that use randomization or probabilistic techniques to achieve space or time efficiency, often allowing for small errors (e.g., false positives).
  \end{block}

  \begin{itemize}
    \item Useful for large-scale data, streaming, or approximate answers
    \item Examples: Bloom filter, Count-Min Sketch, HyperLogLog
  \end{itemize}
\end{frame}

\begin{frame}{Bloom Filter: What and Why?}
  \begin{block}{What is a Bloom Filter?}
    A space-efficient, probabilistic data structure for set membership queries.
  \end{block}

  \begin{itemize}
    \item Answers: "Is $x$ in the set?"
    \item May return false positives, but never false negatives
    \item Very compact compared to hash sets
  \end{itemize}
\end{frame}

\begin{frame}{How Does a Bloom Filter Work?}
  \begin{enumerate}
    \item Start with a bit array of $m$ bits, all set to 0

    \item Use $k$ independent hash functions

    \item To add an element, set $k$ bits (one per hash) to 1

    \item To check membership, test if all $k$ bits are 1
  \end{enumerate}
\end{frame}

\begin{frame}{Bloom Filter Example}
  Suppose $m=8$ bits, $k=2$ hash functions, and we insert $\{\text{cat}, \text{dog}\}$.

  \begin{block}{Bit Array After Insertion}
    \[
      \begin{array}{|c|c|c|c|c|c|c|c|}
        \hline
        1 & 0 & 1 & 1 & 0 & 0 & 0 & 1 \\
        \hline
      \end{array}
    \]
  \end{block}

  \begin{itemize}
    \item To check if "cat" is in the set, hash and check the corresponding bits
    \item If all are 1, answer is "possibly in set"; if any is 0, "definitely not in set"
  \end{itemize}
\end{frame}

\begin{frame}{Bloom Filter: Trade-offs}
  \begin{itemize}
    \item \textbf{False positives:} May say "in set" when not

    \item \textbf{No false negatives:} Never says "not in set" if it is

    \item \textbf{Space efficient:} Much smaller than explicit set

    \item \textbf{No deletions:} Standard Bloom filters do not support removing elements
  \end{itemize}
\end{frame}

% References
\begin{frame}[allowframebreaks]{References}
  \printbibliography
\end{frame}

\end{document}
